# -*- coding: utf-8 -*-
"""CNS_AML_fhe_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b5Or6W0KrAHKzSuPNoEbMMvoIcLTEZ2E
"""

from google.colab import drive
drive.mount('/content/drive')

!git clone https://github.com/rapidsai/rapidsai-csp-utils.git
!python rapidsai-csp-utils/colab/pip-install.py

import cudf
import cuml
import dask_cudf

from cuml.ensemble import RandomForestClassifier as cuRF
from cuml.linear_model import LogisticRegression as cuLR
from cuml.preprocessing import StandardScaler as cuScaler
import dask
import dask.dataframe as dd
from dask.diagnostics import ProgressBar
import numpy as np
import pandas as pd
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import (classification_report, confusion_matrix,
                             roc_auc_score, precision_recall_curve,
                             average_precision_score, roc_curve, f1_score,
                             accuracy_score, precision_score, recall_score)
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

import subprocess
gpu_info = subprocess.check_output(['nvidia-smi']).decode('utf-8')
print("GPU Information:")
print(gpu_info)

sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

print("\nAll libraries imported successfully!")
print(f"cuDF version: {cudf.__version__}")
print(f"cuML version: {cuml.__version__}")
print(f"XGBoost version: {xgb.__version__}")

# CELL 3: Load Data from Google Drive in Batches - GPU Optimized

folder_path = '/content/drive/MyDrive/cleaned_data_json'

print("Loading data using cuDF (GPU-accelerated) in batches...")

batches = [range(0, 5), range(5, 10)]

gdfs = []

for batch_idx, batch_files in enumerate(batches, start=1):
    print(f"\nProcessing batch {batch_idx}...")
    batch_data = []

    for i in batch_files:
        file_path = f'{folder_path}/bank_{i}.json'
        print(f"  Loading {file_path}...")
        try:
            with open(file_path, 'r') as f:
                json_data = json.load(f)
                records = json_data['records']
                batch_data.extend(records)
            print(f"    Loaded {len(records)} transactions")
        except FileNotFoundError:
            print(f"    File not found: {file_path}")
        except Exception as e:
            print(f"    Error loading {file_path}: {e}")

    batch_gdf = cudf.DataFrame(batch_data)
    gdfs.append(batch_gdf)

    del batch_data
    print(f"  Batch {batch_idx} shape: {batch_gdf.shape}")

gdf = cudf.concat(gdfs, ignore_index=True)
del gdfs

print(f"\n{'='*60}")
print(f"Total transactions loaded (GPU): {len(gdf)}")
print(f"{'='*60}")
print(f"Memory usage (GPU): {gdf.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
print("\nFirst few rows:")
gdf.head()

# CELL 4: Initial Data Exploration - GPU
print("="*80)
print("DATA OVERVIEW (GPU-accelerated)")
print("="*80)
print(f"\nDataset Shape: {gdf.shape}")
print(f"\nColumn Names and Types:")
print(gdf.dtypes)

print(f"\nNull Values:")
print(gdf.isnull().sum())

print(f"\nBasic Statistics:")
print(gdf.describe())

print(f"\n{'='*80}")
print("CLASS DISTRIBUTION")
print("="*80)

class_dist = gdf['Is Laundering'].value_counts().reindex([0, 1], fill_value=0)

total = len(gdf)

print(f"\nPercentage:")
for idx in [0, 1]:
    count = class_dist[idx]
    print(f"Is Laundering {idx}: {(count/total)*100:.2f}%")

# CELL 5: Feature Engineering - GPU Accelerated (cuDF + CuPy)
import cupy as cp

print("\nStarting feature engineering with cuDF (GPU-accelerated)...")

gdf['Timestamp'] = cudf.to_datetime(gdf['Timestamp'], format='%Y/%m/%d %H:%M')
gdf['Hour'] = gdf['Timestamp'].dt.hour
gdf['DayOfWeek'] = gdf['Timestamp'].dt.weekday
gdf['Month'] = gdf['Timestamp'].dt.month
gdf['Day'] = gdf['Timestamp'].dt.day

gdf['IsWeekend'] = (gdf['DayOfWeek'] >= 5).astype('int32')
gdf['IsNightTime'] = ((gdf['Hour'] >= 22) | (gdf['Hour'] <= 6)).astype('int32')

gdf['Same_Bank'] = (gdf['From Bank'] == gdf['To Bank']).astype('int32')
gdf['Same_Account'] = (gdf['From_Account'] == gdf['To_Account']).astype('int32')
gdf['Same_Entity'] = (gdf['Sender_Entity ID'] == gdf['Receiver_Entity ID']).astype('int32')

for col in ['Amount Received', 'Amount Paid']:
    gdf[f'Log_{col.replace(" ", "_")}'] = cudf.Series(cp.log1p(gdf[col].to_cupy()))

gdf['Amount_Difference'] = (gdf['Amount Received'] - gdf['Amount Paid']).abs()
gdf['Round_Amount_Received'] = (gdf['Amount Received'] % 1000 == 0).astype('int32')
gdf['Round_Amount_Paid'] = (gdf['Amount Paid'] % 1000 == 0).astype('int32')
gdf['Below_Threshold'] = ((gdf['Amount Received'] > 9000) & (gdf['Amount Received'] < 10000)).astype('int32')

gdf['Currency_Mismatch'] = (gdf['Receiving Currency'] != gdf['Payment Currency']).astype('int32')

categorical_cols = ['Payment Format', 'Receiving Currency', 'Payment Currency']
for col in categorical_cols:
    gdf[f'{col}_Encoded'] = gdf[col].astype('category').cat.codes

print(f"Feature engineering complete!")
print(f"New shape: {gdf.shape}")
gpu_mem_mb = gdf.memory_usage(deep=True).sum() / 1024**2
print(f"GPU Memory usage: {gpu_mem_mb:.2f} MB")

print("Updated columns: ")
print(list(gdf.columns))

# CELL 6: Exploratory Data Analysis - Visualizations
print("\nCreating visualizations (sampling for efficiency)...")
sample_size = min(5000000, len(gdf))
gdf_sample = gdf.sample(n=sample_size, random_state=42)
df_vis = gdf_sample.to_pandas()

fig, axes = plt.subplots(2, 3, figsize=(18, 10))

df_vis['Is Laundering'].value_counts().plot(kind='bar', ax=axes[0, 0], color=['green', 'red'])
axes[0, 0].set_title('Class Distribution')
axes[0, 0].set_xlabel('Is Laundering')
axes[0, 0].set_ylabel('Count')

df_vis.boxplot(column='Amount Received', by='Is Laundering', ax=axes[0, 1])
axes[0, 1].set_title('Amount Received by Class')
axes[0, 1].set_xlabel('Is Laundering')

df_vis.boxplot(column='Log_Amount_Received', by='Is Laundering', ax=axes[0, 2])
axes[0, 2].set_title('Log Amount Received by Class')

pd.crosstab(df_vis['Payment Format_Encoded'], df_vis['Is Laundering']).plot(kind='bar', ax=axes[1, 0])
axes[1, 0].set_title('Payment Format by Class')
axes[1, 0].set_xlabel('Payment Format')
axes[1, 0].legend(['Legitimate', 'Laundering'])

df_vis.groupby(['Hour', 'Is Laundering']).size().unstack(fill_value=0).plot(kind='bar', ax=axes[1, 1])
axes[1, 1].set_title('Transaction Hour by Class')
axes[1, 1].set_xlabel('Hour of Day')
axes[1, 1].legend(['Legitimate', 'Laundering'])

pd.crosstab(df_vis['Same_Bank'], df_vis['Is Laundering']).plot(kind='bar', ax=axes[1, 2])
axes[1, 2].set_title('Same Bank Transfer by Class')
axes[1, 2].set_xlabel('Same Bank')
axes[1, 2].legend(['Legitimate', 'Laundering'])

plt.tight_layout()
plt.show()

del df_vis, gdf_sample

# CELL 7: Prepare Data for Modeling - GPU
print("Preparing data for modeling on GPU...")

feature_columns = [
    'From Bank', 'To Bank', 'Amount Received', 'Amount Paid',
    'Hour', 'DayOfWeek', 'Month', 'Day', 'IsWeekend', 'IsNightTime',
    'Same_Bank', 'Same_Account', 'Same_Entity',
    'Amount_Difference', 'Log_Amount_Received', 'Log_Amount_Paid',
    'Round_Amount_Received', 'Round_Amount_Paid', 'Below_Threshold',
    'Currency_Mismatch', 'Payment Format_Encoded',
    'Receiving Currency_Encoded', 'Payment Currency_Encoded',
    'Bank_Partition'
]

print(f"\nFeatures being used ({len(feature_columns)} features):")
for i, col in enumerate(feature_columns, 1):
    print(f"{i}. {col}")

gdf_model = gdf[feature_columns + ['Is Laundering']]

X_gpu = gdf_model[feature_columns].values
y_gpu = gdf_model['Is Laundering'].values

print(f"\nFeatures shape: {X_gpu.shape}")
print(f"Target shape: {y_gpu.shape}")

X = X_gpu.get() if hasattr(X_gpu, 'get') else X_gpu
y = y_gpu.get() if hasattr(y_gpu, 'get') else y_gpu

X_pd = pd.DataFrame(X, columns=feature_columns)
y_pd = pd.Series(y)

class_0 = X_pd[y_pd == 0]
class_1 = X_pd[y_pd == 1]

desired_class_1_count = len(class_1)
desired_class_0_count = int((desired_class_1_count / 0.3) * 0.7)

if len(class_0) > desired_class_0_count:
    class_0_sampled = class_0.sample(n=desired_class_0_count, random_state=42)
else:
    class_0_sampled = class_0

X_balanced = pd.concat([class_0_sampled, class_1])
y_balanced = pd.Series([0]*len(class_0_sampled) + [1]*len(class_1))


X_train, X_test, y_train, y_test = train_test_split(
    X_balanced.values, y_balanced.values, test_size=0.2, random_state=42, stratify=y_balanced
)

del X_pd, y_pd, class_0, class_1, class_0_sampled, X_balanced, y_balanced

unique, counts = np.unique(y_train, return_counts=True)


X_train_gpu = cudf.DataFrame(X_train, columns=feature_columns)
X_test_gpu = cudf.DataFrame(X_test, columns=feature_columns)
y_train_gpu = cudf.Series(y_train)
y_test_gpu = cudf.Series(y_test)

print("\nScaling features on GPU...")
scaler = cuScaler()
X_train_scaled = scaler.fit_transform(X_train_gpu)
X_test_scaled = scaler.transform(X_test_gpu)

print("Data prepared for modeling on GPU!")

del X_gpu, y_gpu, X, y, X_train, X_test, y_train

# Model 1 - Logistic Regression (GPU)
print("="*80)
print("LOGISTIC REGRESSION (cuML - GPU Accelerated)")
print("="*80)

from cuml.linear_model import LogisticRegression as cuLR
from sklearn.metrics import (
    classification_report, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score, confusion_matrix
)
import matplotlib.pyplot as plt
import seaborn as sns

lr_model = cuLR(
    max_iter=1000,
    class_weight='balanced',
    penalty='l2',
    tol=1e-4
)

print("Training model on GPU...")
lr_model.fit(X_train_scaled, y_train_gpu)

print("Making predictions on GPU...")
y_pred_gpu = lr_model.predict(X_test_scaled)

y_pred_proba_gpu = lr_model.predict_proba(X_test_scaled)

if hasattr(y_pred_proba_gpu, 'to_pandas'):
    y_pred_proba_np = y_pred_proba_gpu.to_pandas().values
else:
    y_pred_proba_np = y_pred_proba_gpu

if y_pred_proba_np.shape[1] == 1:
    y_pred_proba_lr = y_pred_proba_np[:, 0]
else:
    y_pred_proba_lr = y_pred_proba_np[:, 1]

y_pred_lr = y_pred_gpu.to_pandas().values if hasattr(y_pred_gpu, 'to_pandas') else y_pred_gpu

print("\nClassification Report:")
print(classification_report(y_test, y_pred_lr, digits=4))

print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_lr):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_lr):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_lr):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}")

cm = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Logistic Regression (GPU)')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

!pip install tenseal pycryptodome -q

import tenseal as ts
import time
import numpy as np
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

print("TenSEAL imported successfully!")
print(f"TenSEAL version: {ts.__version__}")

class FHELogisticRegression:
    def __init__(self, poly_modulus_degree=16384, coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 60]):
        self.context = None
        self.weights_enc = None
        self.bias_enc = None
        self.weights_plain = None
        self.bias_plain = None
        self.poly_modulus_degree = poly_modulus_degree
        self.coeff_mod_bit_sizes = coeff_mod_bit_sizes

    def setup_context(self):

        self.context = ts.context(
            ts.SCHEME_TYPE.CKKS,
            poly_modulus_degree=self.poly_modulus_degree,
            coeff_mod_bit_sizes=self.coeff_mod_bit_sizes
        )

        self.context.generate_galois_keys()

        self.context.global_scale = 2**40

        print(f"Context created with poly_modulus_degree={self.poly_modulus_degree}")
        print(f"Context configured for encrypted computation")

    def encrypt_model(self, model):
        """
        Encrypt trained model parameters

        Args:
            model: Trained sklearn LogisticRegression model
        """
        print("\nEncrypting model parameters...")

        coef = model.coef_


        if hasattr(coef, 'to_numpy'):

            self.weights_plain = coef.to_numpy().flatten().tolist()
        elif hasattr(coef, 'values'):

            self.weights_plain = coef.values.flatten().tolist()
        else:
            self.weights_plain = coef.flatten().tolist()

        intercept = model.intercept_[0]
        if hasattr(intercept, 'item'):
            self.bias_plain = float(intercept.item())
        else:
            self.bias_plain = float(intercept)

        self.weights_enc = ts.ckks_vector(self.context, self.weights_plain)
        self.bias_enc = ts.ckks_vector(self.context, [self.bias_plain])

        print(f"Encrypted {len(self.weights_plain)} weights")
        print(f"Encrypted bias: {self.bias_plain:.4f}")

    def encrypt_data(self, X):
        if isinstance(X, np.ndarray):
            X = X.tolist()
        return ts.ckks_vector(self.context, X)

    def sigmoid_approximation(self, x_enc):
        result = x_enc * 0.25
        result = result + 0.5
        return result

    def predict_encrypted(self, x_enc):

        z_enc = self.weights_enc.dot(x_enc)
        z_enc = z_enc + self.bias_enc

        y_enc = self.sigmoid_approximation(z_enc)

        return y_enc

    def decrypt_prediction(self, y_enc):

        decrypted = y_enc.decrypt()
        return decrypted[0] if isinstance(decrypted, list) else decrypted

print("FHELogisticRegression class defined")

#Initialize FHE and Encrypt Model

print("="*80)
print("FHE LOGISTIC REGRESSION - ENCRYPTED INFERENCE")
print("="*80)

fhe_lr = FHELogisticRegression(
    poly_modulus_degree=16384,
    coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 60]
)

fhe_lr.context = ts.context(
    ts.SCHEME_TYPE.CKKS,
    poly_modulus_degree=fhe_lr.poly_modulus_degree,
    coeff_mod_bit_sizes=fhe_lr.coeff_mod_bit_sizes
)

fhe_lr.context.generate_galois_keys()

fhe_lr.context.global_scale = 2**40

print(f"Context created with poly_modulus_degree={fhe_lr.poly_modulus_degree}")
print(f"Context configured for encrypted computation")

print("\nEncrypting model parameters...")

coef = lr_model.coef_

if hasattr(coef, 'to_numpy'):
    fhe_lr.weights_plain = coef.to_numpy().flatten().tolist()
elif hasattr(coef, 'values'):
    fhe_lr.weights_plain = coef.values.flatten().tolist()
else:
    fhe_lr.weights_plain = coef.flatten().tolist()

intercept = lr_model.intercept_[0]
if hasattr(intercept, 'item'):
    fhe_lr.bias_plain = float(intercept.item())
else:
    fhe_lr.bias_plain = float(intercept)

fhe_lr.weights_enc = ts.ckks_vector(fhe_lr.context, fhe_lr.weights_plain)
fhe_lr.bias_enc = ts.ckks_vector(fhe_lr.context, [fhe_lr.bias_plain])

print(f"Encrypted {len(fhe_lr.weights_plain)} weights")
print(f"Encrypted bias: {fhe_lr.bias_plain:.4f}")

print("\nModel encrypted and ready for inference!")

# Encrypted Inference on Test Set
print("\n" + "="*80)
print("PERFORMING ENCRYPTED INFERENCE")
print("="*80)

n_samples = 2000
print(f"\nTesting on {n_samples} samples from test set...")

if hasattr(lr_model, 'feature_names_in_'):
    feature_columns = lr_model.feature_names_in_
    if hasattr(feature_columns, 'to_pandas'):
        feature_columns = feature_columns.to_pandas().tolist()
    elif hasattr(feature_columns, 'tolist'):
        feature_columns = feature_columns.tolist()

elif hasattr(X_test_scaled, 'columns'):
    feature_columns = X_test_scaled.columns.to_list()
    print(f"Using {len(feature_columns)} features from test set")
else:
    n_features = X_test_scaled.shape[1] if hasattr(X_test_scaled, 'shape') else len(X_test_scaled[0])
    feature_columns = list(range(n_features))
    print(f"Using {len(feature_columns)} numeric feature names")

if hasattr(X_test_scaled, 'to_pandas'):
    X_test_np = X_test_scaled.to_pandas().values[:n_samples]
else:
    X_test_np = X_test_scaled[:n_samples]

if hasattr(y_test, 'to_pandas'):
    y_test_subset = y_test.to_pandas().values[:n_samples]
elif hasattr(y_test, 'values'):
    y_test_subset = y_test.values[:n_samples]
else:
    y_test_subset = y_test[:n_samples]

plaintext_preds = []
encrypted_preds = []
plaintext_times = []
encrypted_times = []

print("\nProcessing samples...")
for i in range(n_samples):
    if (i + 1) % 10 == 0:
        print(f"  Processed {i+1}/{n_samples} samples...")

    sample = X_test_np[i]

    start = time.time()
    sample_dict = {col: [val] for col, val in zip(feature_columns, sample)}
    sample_df = cudf.DataFrame(sample_dict)
    plain_pred = lr_model.predict_proba(sample_df).iloc[0, 1]
    plaintext_time = time.time() - start
    plaintext_preds.append(1 if plain_pred > 0.5 else 0)
    plaintext_times.append(plaintext_time)

    start = time.time()
    x_enc = fhe_lr.encrypt_data(sample)
    y_enc = fhe_lr.predict_encrypted(x_enc)
    enc_pred = fhe_lr.decrypt_prediction(y_enc)

    encrypted_time = time.time() - start
    encrypted_preds.append(1 if enc_pred > 0.5 else 0)
    encrypted_times.append(encrypted_time)

print(f"\nCompleted {n_samples} encrypted inferences!")

#Evaluation & Benchmarking
print("\n" + "="*80)
print("PERFORMANCE COMPARISON")
print("="*80)

plain_acc = accuracy_score(y_test_subset, plaintext_preds)
enc_acc = accuracy_score(y_test_subset, encrypted_preds)
accuracy_loss = (plain_acc - enc_acc) / plain_acc * 100

avg_plain_time = np.mean(plaintext_times) * 1000
avg_enc_time = np.mean(encrypted_times) * 1000
time_overhead = avg_enc_time / avg_plain_time

print("\n ACCURACY COMPARISON:")
print(f"  Plaintext Accuracy:  {plain_acc:.4f}")
print(f"  Encrypted Accuracy:  {enc_acc:.4f}")
print(f"  Accuracy Loss:       {accuracy_loss:.2f}%")

print("\n RUNTIME COMPARISON:")
print(f"  Avg Plaintext Time:  {avg_plain_time:.2f} ms")
print(f"  Avg Encrypted Time:  {avg_enc_time:.2f} ms")
print(f"  Overhead Factor:     {time_overhead:.1f}x slower")

print("\n DETAILED CLASSIFICATION REPORT (Encrypted):")
print(classification_report(y_test_subset, encrypted_preds, digits=4))

cm = confusion_matrix(y_test_subset, encrypted_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Encrypted FHE Inference')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

print("\n CONFUSION MATRIX VALUES:")
print(f"True Negatives (Legitimate correctly identified): {cm[0, 0]}")
print(f"False Positives (Legitimate misclassified as Laundering): {cm[0, 1]}")
print(f"False Negatives (Laundering misclassified as Legitimate): {cm[1, 0]}")
print(f"True Positives (Laundering correctly identified): {cm[1, 1]}")

# Visualization - Comparison Charts
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

ax1 = axes[0, 0]
models = ['Plaintext\nLogistic Regression', 'Encrypted\nLogistic Regression']
accuracies = [plain_acc, enc_acc]
colors = ['#2ecc71', '#3498db']
bars = ax1.bar(models, accuracies, color=colors, alpha=0.7, edgecolor='black')
ax1.set_ylabel('Accuracy', fontsize=12)
ax1.set_title('Accuracy: Plaintext vs Encrypted', fontsize=14, fontweight='bold')
ax1.set_ylim([0, 1])
ax1.axhline(y=plain_acc, color='red', linestyle='--', alpha=0.5, label=f'Baseline: {plain_acc:.4f}')
for bar in bars:
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.4f}', ha='center', va='bottom', fontsize=11)
ax1.legend()
ax1.grid(axis='y', alpha=0.3)

ax2 = axes[0, 1]
runtimes = [avg_plain_time, avg_enc_time]
bars = ax2.bar(models, runtimes, color=['#e74c3c', '#9b59b6'], alpha=0.7, edgecolor='black')
ax2.set_ylabel('Time (ms)', fontsize=12)
ax2.set_title('Average Inference Time', fontsize=14, fontweight='bold')
ax2.set_yscale('log')
for bar in bars:
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.1f}ms', ha='center', va='bottom', fontsize=11)
ax2.grid(axis='y', alpha=0.3)

ax3 = axes[1, 0]
from sklearn.metrics import confusion_matrix
cm_enc = confusion_matrix(y_test_subset, encrypted_preds)
sns.heatmap(cm_enc, annot=True, fmt='d', cmap='Blues', ax=ax3,
            xticklabels=['Legitimate', 'Laundering'],
            yticklabels=['Legitimate', 'Laundering'])
ax3.set_title('Confusion Matrix - Encrypted Inference', fontsize=14, fontweight='bold')
ax3.set_ylabel('Actual', fontsize=12)
ax3.set_xlabel('Predicted', fontsize=12)

ax4 = axes[1, 1]
ax4.axis('off')

security_bits = 128

summary_text = f"""
FHE PERFORMANCE SUMMARY
=======================

Accuracy Metrics
  Plaintext:      {plain_acc:.4f}
  Encrypted:      {enc_acc:.4f}
  Loss:           {accuracy_loss:.2f}%

Runtime Metrics
  Plaintext:      {avg_plain_time:.2f} ms
  Encrypted:      {avg_enc_time:.2f} ms
  Overhead:       {time_overhead:.1f}x

Security Parameters
  Scheme:         CKKS
  Poly Degree:    {fhe_lr.poly_modulus_degree}
  Security Level: {security_bits} bits (estimated)

Memory Impact
  Features:       {len(fhe_lr.weights_plain)}
  Ciphertext Size: ~{len(fhe_lr.weights_plain) * 8} KB

Conclusion
  FHE enables privacy-preserving ML
  with acceptable accuracy trade-off
  and manageable computational cost.
"""
ax4.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',
         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('fhe_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nVisualization saved as 'fhe_comparison.png'")